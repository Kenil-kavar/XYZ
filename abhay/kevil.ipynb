{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U git+https://github.com/huggingface/transformers -q","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-14T08:37:47.317005Z","iopub.execute_input":"2024-09-14T08:37:47.317577Z","iopub.status.idle":"2024-09-14T08:38:40.281108Z","shell.execute_reply.started":"2024-09-14T08:37:47.317540Z","shell.execute_reply":"2024-09-14T08:38:40.279904Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!wget https://d8it4huxumps7.cloudfront.net/files/66e31d6ee96cd_student_resource_3.zip\n!unzip 66e31d6ee96cd_student_resource_3.zip\n!rm 66e31d6ee96cd_student_resource_3.zip","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:38:40.283018Z","iopub.execute_input":"2024-09-14T08:38:40.283375Z","iopub.status.idle":"2024-09-14T08:38:43.584440Z","shell.execute_reply.started":"2024-09-14T08:38:40.283339Z","shell.execute_reply":"2024-09-14T08:38:43.583383Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2024-09-14 08:38:41--  https://d8it4huxumps7.cloudfront.net/files/66e31d6ee96cd_student_resource_3.zip\nResolving d8it4huxumps7.cloudfront.net (d8it4huxumps7.cloudfront.net)... 18.65.229.18, 18.65.229.59, 18.65.229.45, ...\nConnecting to d8it4huxumps7.cloudfront.net (d8it4huxumps7.cloudfront.net)|18.65.229.18|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5184192 (4.9M) [application/zip]\nSaving to: '66e31d6ee96cd_student_resource_3.zip'\n\n66e31d6ee96cd_stude 100%[===================>]   4.94M  --.-KB/s    in 0.07s   \n\n2024-09-14 08:38:41 (75.3 MB/s) - '66e31d6ee96cd_student_resource_3.zip' saved [5184192/5184192]\n\nArchive:  66e31d6ee96cd_student_resource_3.zip\n   creating: student_resource 3/\n  inflating: __MACOSX/._student_resource 3  \n  inflating: student_resource 3/sample_code.py  \n  inflating: __MACOSX/student_resource 3/._sample_code.py  \n  inflating: student_resource 3/.DS_Store  \n  inflating: __MACOSX/student_resource 3/._.DS_Store  \n   creating: student_resource 3/dataset/\n  inflating: __MACOSX/student_resource 3/._dataset  \n  inflating: student_resource 3/README.md  \n  inflating: __MACOSX/student_resource 3/._README.md  \n   creating: student_resource 3/src/\n  inflating: __MACOSX/student_resource 3/._src  \n  inflating: student_resource 3/dataset/sample_test_out.csv  \n  inflating: __MACOSX/student_resource 3/dataset/._sample_test_out.csv  \n  inflating: student_resource 3/dataset/sample_test_out_fail.csv  \n  inflating: __MACOSX/student_resource 3/dataset/._sample_test_out_fail.csv  \n  inflating: student_resource 3/dataset/test.csv  \n  inflating: __MACOSX/student_resource 3/dataset/._test.csv  \n  inflating: student_resource 3/dataset/sample_test.csv  \n  inflating: __MACOSX/student_resource 3/dataset/._sample_test.csv  \n  inflating: student_resource 3/dataset/train.csv  \n  inflating: __MACOSX/student_resource 3/dataset/._train.csv  \n  inflating: student_resource 3/src/sanity.py  \n  inflating: __MACOSX/student_resource 3/src/._sanity.py  \n  inflating: student_resource 3/src/.DS_Store  \n  inflating: __MACOSX/student_resource 3/src/._.DS_Store  \n  inflating: student_resource 3/src/constants.py  \n  inflating: __MACOSX/student_resource 3/src/._constants.py  \n  inflating: student_resource 3/src/utils.py  \n  inflating: __MACOSX/student_resource 3/src/._utils.py  \n  inflating: student_resource 3/src/test.ipynb  \n  inflating: __MACOSX/student_resource 3/src/._test.ipynb  \n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\nimport pandas as pd\nfrom torchvision import transforms\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport os\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:38:43.585841Z","iopub.execute_input":"2024-09-14T08:38:43.586157Z","iopub.status.idle":"2024-09-14T08:39:01.045133Z","shell.execute_reply.started":"2024-09-14T08:38:43.586125Z","shell.execute_reply":"2024-09-14T08:39:01.044172Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"entity_unit_map = {\n    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'item_weight': {'gram',\n        'kilogram',\n        'microgram',\n        'milligram',\n        'ounce',\n        'pound',\n        'ton'},\n    'maximum_weight_recommendation': {'gram',\n        'kilogram',\n        'microgram',\n        'milligram',\n        'ounce',\n        'pound',\n        'ton'},\n    'voltage': {'kilovolt', 'millivolt', 'volt'},\n    'wattage': {'kilowatt', 'watt'},\n    'item_volume': {'centilitre',\n        'cubic foot',\n        'cubic inch',\n        'cup',\n        'decilitre',\n        'fluid ounce',\n        'gallon',\n        'imperial gallon',\n        'litre',\n        'microlitre',\n        'millilitre',\n        'pint',\n        'quart'}\n}\n\nenglish = {}\n\n\nfor k in entity_unit_map.keys():\n    english[k] = k\n    \nenglish[\"item_weight\"] = \"weight\"\nenglish[\"item_volume\"] = \"volume\"\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:01.047792Z","iopub.execute_input":"2024-09-14T08:39:01.048544Z","iopub.status.idle":"2024-09-14T08:39:01.058795Z","shell.execute_reply.started":"2024-09-14T08:39:01.048496Z","shell.execute_reply":"2024-09-14T08:39:01.057479Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/working/student_resource 3/dataset/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:01.062789Z","iopub.execute_input":"2024-09-14T08:39:01.063193Z","iopub.status.idle":"2024-09-14T08:39:01.547697Z","shell.execute_reply.started":"2024-09-14T08:39:01.063147Z","shell.execute_reply":"2024-09-14T08:39:01.546668Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = Qwen2VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n)\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:01.549375Z","iopub.execute_input":"2024-09-14T08:39:01.549688Z","iopub.status.idle":"2024-09-14T08:39:25.347424Z","shell.execute_reply.started":"2024-09-14T08:39:01.549654Z","shell.execute_reply":"2024-09-14T08:39:25.346588Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dab38fa9f37d47b499a86fe2c9610574"}},"metadata":{}},{"name":"stderr","text":"Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/56.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b9eb43c78948c3b2b8731f4b6b1bf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b504ce291f434f2eb993b392bc5832d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82423202ad2e47369c512fcd40c51a5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84b2badd0bc44ab18bd7358cf085bf61"}},"metadata":{}},{"name":"stderr","text":"`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b804878c65004fb4b0b23c614e5c6a9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5363eed07bf4a05b6fb82608dedc829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4f05a0f283479b9777e493b72d8122"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e799c2649764ca08ee7f62d6e467b92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"417e58988c6041a5aefd49fb9a559431"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38d0926f313b43fdae664b7faafe2863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75bece846ace441a9dce55f133b0738a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56ea60101c0d4fc3b4168a42c6a024a8"}},"metadata":{}}]},{"cell_type":"markdown","source":"<h1> Download images parallely </h1>\n","metadata":{}},{"cell_type":"code","source":"subset = df[:20]\n\nprint(subset[\"image_link\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:55:50.302323Z","iopub.execute_input":"2024-09-14T08:55:50.303196Z","iopub.status.idle":"2024-09-14T08:55:50.310141Z","shell.execute_reply.started":"2024-09-14T08:55:50.303141Z","shell.execute_reply":"2024-09-14T08:55:50.309157Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"0     https://m.media-amazon.com/images/I/61I9XdN6OF...\n1     https://m.media-amazon.com/images/I/71gSRbyXmo...\n2     https://m.media-amazon.com/images/I/61BZ4zrjZX...\n3     https://m.media-amazon.com/images/I/612mrlqiI4...\n4     https://m.media-amazon.com/images/I/617Tl40LOX...\n5     https://m.media-amazon.com/images/I/61QsBSE7jg...\n6     https://m.media-amazon.com/images/I/81xsq6vf2q...\n7     https://m.media-amazon.com/images/I/71DiLRHeZd...\n8     https://m.media-amazon.com/images/I/91Cma3Rzse...\n9     https://m.media-amazon.com/images/I/71jBLhmTNl...\n10    https://m.media-amazon.com/images/I/81N73b5khV...\n11    https://m.media-amazon.com/images/I/61oMj2iXOu...\n12    https://m.media-amazon.com/images/I/91LPf6OjV9...\n13    https://m.media-amazon.com/images/I/81fOxWWWKY...\n14    https://m.media-amazon.com/images/I/81dzao1Ob4...\n15    https://m.media-amazon.com/images/I/91-iahVGED...\n16    https://m.media-amazon.com/images/I/81S2+GnYpT...\n17    https://m.media-amazon.com/images/I/81e2YtCOKv...\n18    https://m.media-amazon.com/images/I/81RNsNEM1E...\n19    https://m.media-amazon.com/images/I/91prZeizZn...\nName: image_link, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install constants","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:25.354415Z","iopub.execute_input":"2024-09-14T08:39:25.354709Z","iopub.status.idle":"2024-09-14T08:39:47.400480Z","shell.execute_reply.started":"2024-09-14T08:39:25.354678Z","shell.execute_reply":"2024-09-14T08:39:47.399304Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting constants\n  Downloading constants-2023.2.0.tar.gz (5.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tox (from constants)\n  Downloading tox-4.18.1-py3-none-any.whl.metadata (5.0 kB)\nINFO: pip is looking at multiple versions of constants to determine which version is compatible with other requirements. This could take a while.\nCollecting constants\n  Downloading constants-0.6.0.tar.gz (5.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: constants\n  Building wheel for constants (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for constants: filename=constants-0.6.0-py3-none-any.whl size=5458 sha256=edc823dc36abd167d556f7ecd43504f346c4629156ff664e38c4df01c89c3dba\n  Stored in directory: /root/.cache/pip/wheels/5b/96/3c/386c2342a8a1bdd317f2f250bd076c13938c6f598c4a40ec14\nSuccessfully built constants\nInstalling collected packages: constants\nSuccessfully installed constants-0.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport constants\nimport os\nimport requests\nimport pandas as pd\nimport multiprocessing\nimport time\nfrom time import time as timer\nfrom tqdm import tqdm\nimport numpy as np\nfrom pathlib import Path\nfrom functools import partial\nimport requests\nimport urllib\nfrom PIL import Image\n\ndef create_placeholder_image(image_save_path):\n    try:\n        placeholder_image = Image.new('RGB', (100, 100), color='black')\n        placeholder_image.save(image_save_path)\n    except Exception as e:\n        return\n\ndef download_image(image_link, save_folder, retries=3, delay=3):\n    if not isinstance(image_link, str):\n        return\n\n    filename = Path(image_link).name\n    image_save_path = os.path.join(save_folder, filename)\n    print(image_save_path)\n\n    if os.path.exists(image_save_path):\n        return\n\n    for _ in range(retries):\n        try:\n            urllib.request.urlretrieve(image_link, image_save_path)\n            return\n        except:\n            time.sleep(delay)\n    \n    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n\ndef download_images(image_links, download_folder, allow_multiprocessing=True):\n    if not os.path.exists(download_folder):\n        os.makedirs(download_folder)\n\n    if allow_multiprocessing:\n        download_image_partial = partial(\n            download_image, save_folder=download_folder, retries=3, delay=3)\n\n        with multiprocessing.Pool(64) as pool:\n            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n            pool.close()\n            pool.join()\n    else:\n        for image_link in tqdm(image_links, total=len(image_links)):\n            download_image(image_link, save_folder=download_folder, retries=3, delay=3)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:55:57.218062Z","iopub.execute_input":"2024-09-14T08:55:57.218963Z","iopub.status.idle":"2024-09-14T08:55:57.231049Z","shell.execute_reply.started":"2024-09-14T08:55:57.218921Z","shell.execute_reply":"2024-09-14T08:55:57.229975Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import os\nos.makedirs(\"downloaded_images\", exist_ok=True)\n\n\nsave_dir = \"downloaded_images\"\nimage_urls = subset['image_link'].tolist()\n\ndownload_images(image_urls, save_dir, allow_multiprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:55:59.569202Z","iopub.execute_input":"2024-09-14T08:55:59.569589Z","iopub.status.idle":"2024-09-14T08:56:01.326657Z","shell.execute_reply.started":"2024-09-14T08:55:59.569553Z","shell.execute_reply":"2024-09-14T08:56:01.325425Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"downloaded_images/61I9XdN6OFL.jpgdownloaded_images/612mrlqiI4L.jpgdownloaded_images/71gSRbyXmoL.jpgdownloaded_images/61QsBSE7jgL.jpgdownloaded_images/61BZ4zrjZXL.jpg\n\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\ndownloaded_images/81xsq6vf2qL.jpg\ndownloaded_images/617Tl40LOXL.jpgdownloaded_images/71jBLhmTNlL.jpg\n\ndownloaded_images/81S2+GnYpTL.jpgdownloaded_images/91Cma3RzseL.jpgdownloaded_images/81RNsNEM1EL.jpgdownloaded_images/91-iahVGEDL.jpgdownloaded_images/81dzao1Ob4L.jpgdownloaded_images/81N73b5khVL.jpgdownloaded_images/91prZeizZnL.jpgdownloaded_images/91LPf6OjV9L.jpg\ndownloaded_images/71DiLRHeZdL.jpgdownloaded_images/81e2YtCOKvL.jpg\n\ndownloaded_images/81fOxWWWKYL.jpg\n\ndownloaded_images/61oMj2iXOuL.jpg\n\n\n\n\n\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20/20 [00:00<00:00, 68.23it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((600, 600)),\n    transforms.ToTensor(),\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:08.534241Z","iopub.execute_input":"2024-09-14T08:56:08.535079Z","iopub.status.idle":"2024-09-14T08:56:08.540278Z","shell.execute_reply.started":"2024-09-14T08:56:08.535039Z","shell.execute_reply":"2024-09-14T08:56:08.539184Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\ndef url_to_image(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    resized = trans(img)\n    return resized\n\n# Replace the 'image_link' column with PIL.Image objects\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:10.680522Z","iopub.execute_input":"2024-09-14T08:56:10.681337Z","iopub.status.idle":"2024-09-14T08:56:10.686219Z","shell.execute_reply.started":"2024-09-14T08:56:10.681298Z","shell.execute_reply":"2024-09-14T08:56:10.685332Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def get_message(entity_name):\n    message = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image\",\n                    },\n                    {\"type\": \"text\", \"text\": f\"What is the {english[entity_name]} of the item in the image\"},\n                ],\n            }\n        ]\n    return message","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:11.760138Z","iopub.execute_input":"2024-09-14T08:56:11.760998Z","iopub.status.idle":"2024-09-14T08:56:11.765909Z","shell.execute_reply.started":"2024-09-14T08:56:11.760960Z","shell.execute_reply":"2024-09-14T08:56:11.764856Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from typing import List\ndef forward(entity_names, images):\n    \"\"\"\n    entity_name -> It is a list of entity names in the batch\n    images -> List of images\n    \"\"\"\n    \n    messages = [ get_message(entity)  for entity in entity_names]\n    \n    texts = [\n        processor.apply_chat_template(msg, add_generation_prompt=True) \n        for msg in messages ]\n\n    \n    #text = processor.apply_chat_template(messages, add_generation_prompt=True)\n\n    \n    inputs = processor(\n        text=texts, \n        images=images, \n        padding=True, \n        return_tensors=\"pt\"\n    )\n\n    inputs = inputs.to(\"cuda\")\n    \n    \n    output_ids = model.generate(**inputs, max_new_tokens=32)\n    \n    generated_ids = [\n        output_ids[len(input_ids) :]\n        for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n    ]\n    del inputs\n    output_text = processor.batch_decode(\n        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n    )\n\n    del generated_ids\n    del output_ids\n\n    \n    \n    \n    return output_text","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:13.426071Z","iopub.execute_input":"2024-09-14T08:56:13.426912Z","iopub.status.idle":"2024-09-14T08:56:13.434918Z","shell.execute_reply.started":"2024-09-14T08:56:13.426874Z","shell.execute_reply":"2024-09-14T08:56:13.433792Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def get_local_filename(image_link):\n    # Extract just the filename from the URL\n    return os.path.basename(image_link)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:14.951074Z","iopub.execute_input":"2024-09-14T08:56:14.951732Z","iopub.status.idle":"2024-09-14T08:56:14.956387Z","shell.execute_reply.started":"2024-09-14T08:56:14.951691Z","shell.execute_reply":"2024-09-14T08:56:14.955448Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"imgs = []\nenames = []\nvalues = []","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:15.968612Z","iopub.execute_input":"2024-09-14T08:56:15.969283Z","iopub.status.idle":"2024-09-14T08:56:15.973521Z","shell.execute_reply.started":"2024-09-14T08:56:15.969242Z","shell.execute_reply":"2024-09-14T08:56:15.972599Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"\nfor ix, row in subset.iterrows():\n    image_link = row[\"image_link\"]\n    local_filename = get_local_filename(image_link)\n    img_path = os.path.join(\"downloaded_images\", local_filename)\n    \n    if os.path.exists(img_path):\n        # Open and transform the image\n        with Image.open(img_path).convert('RGB') as img:\n            img_tensor = transform(img)\n        imgs.append(img_tensor)\n        \n        ename = row[\"entity_name\"]\n        enames.append(ename)\n        \n        value = row[\"entity_value\"]  # Assuming entity_value is in the same row\n        values.append(value)\n    else:\n        print(f\"Warning: File not found: {img_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:17.244228Z","iopub.execute_input":"2024-09-14T08:56:17.245021Z","iopub.status.idle":"2024-09-14T08:56:18.497631Z","shell.execute_reply.started":"2024-09-14T08:56:17.244983Z","shell.execute_reply":"2024-09-14T08:56:18.496760Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import time \nimport torch\n\nimages_tensor = torch.stack(imgs)\n\nstart = time.time()\noutput = forward(enames, imgs)\nend = time.time()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:56:29.761965Z","iopub.execute_input":"2024-09-14T08:56:29.762430Z","iopub.status.idle":"2024-09-14T08:56:35.334845Z","shell.execute_reply.started":"2024-09-14T08:56:29.762391Z","shell.execute_reply":"2024-09-14T08:56:35.333179Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m images_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(imgs)\n\u001b[1;32m      6\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43menames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n","Cell \u001b[0;32mIn[45], line 28\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(entity_names, images)\u001b[0m\n\u001b[1;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(\n\u001b[1;32m     19\u001b[0m     text\u001b[38;5;241m=\u001b[39mtexts, \n\u001b[1;32m     20\u001b[0m     images\u001b[38;5;241m=\u001b[39mimages, \n\u001b[1;32m     21\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     22\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m     output_ids[\u001b[38;5;28mlen\u001b[39m(input_ids) :]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_ids, output_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs\u001b[38;5;241m.\u001b[39minput_ids, output_ids)\n\u001b[1;32m     33\u001b[0m ]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2050\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2042\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2043\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2044\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2045\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2046\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2047\u001b[0m     )\n\u001b[1;32m   2049\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2050\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2061\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2062\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2063\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2064\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2069\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2070\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:3000\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2997\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2999\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3000\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3003\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1683\u001b[0m, in \u001b[0;36mQwen2VLForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas)\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1682\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual\u001b[38;5;241m.\u001b[39mget_dtype())\n\u001b[0;32m-> 1683\u001b[0m     image_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_thw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1684\u001b[0m     image_mask \u001b[38;5;241m=\u001b[39m input_ids \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mimage_token_id\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1120\u001b[0m, in \u001b[0;36mQwen2VisionTransformerPretrainedModel.forward\u001b[0;34m(self, hidden_states, grid_thw)\u001b[0m\n\u001b[1;32m   1117\u001b[0m cu_seqlens \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(cu_seqlens, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1120\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerger(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:430\u001b[0m, in \u001b[0;36mQwen2VLVisionBlock.forward\u001b[0;34m(self, hidden_states, cu_seqlens, rotary_pos_emb)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, cu_seqlens, rotary_pos_emb) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 430\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrotary_pos_emb\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(hidden_states))\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:403\u001b[0m, in \u001b[0;36mVisionSdpaAttention.forward\u001b[0;34m(self, hidden_states, cu_seqlens, rotary_pos_emb)\u001b[0m\n\u001b[1;32m    401\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    402\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 403\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    405\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(seq_length, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 37.10 GiB. GPU 0 has a total capacity of 15.89 GiB of which 6.56 GiB is free. Process 5388 has 9.33 GiB memory in use. Of the allocated memory 8.63 GiB is allocated by PyTorch, and 427.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 37.10 GiB. GPU 0 has a total capacity of 15.89 GiB of which 6.56 GiB is free. Process 5388 has 9.33 GiB memory in use. Of the allocated memory 8.63 GiB is allocated by PyTorch, and 427.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}]},{"cell_type":"code","source":"execution_time = end - start  # Calculate the difference\nprint(f\"Execution time: {execution_time} seconds\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.875539Z","iopub.status.idle":"2024-09-14T08:39:49.875926Z","shell.execute_reply.started":"2024-09-14T08:39:49.875743Z","shell.execute_reply":"2024-09-14T08:39:49.875763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\n# Dictionary to map unit abbreviations to full forms\nunit_mapping = {\n    'g': 'gram',\n    'kg': 'kilogram',\n    'mg': 'milligram',\n    'ug': 'microgram',\n    'lb': 'pound',\n    'oz': 'ounce',\n    'ton': 'ton',\n    'mm': 'millimeter',\n    'cm': 'centimeter',\n    'm': 'meter',\n    'ft': 'foot',\n    'in': 'inch',\n    'yd': 'yard'\n}\n\n# Function to convert the sentence\ndef extract_measurement(sentence):\n    # Regular expression to match number and unit\n    match = re.search(r'(\\d+(\\.\\d+)?)\\s*(\\w+)', sentence)\n    \n    if match:\n        number = match.group(1)\n        unit = match.group(3)\n        \n        # Convert unit to full form\n        full_unit = unit_mapping.get(unit, unit)\n        \n        # Form the final string\n        result = f\"{number} {full_unit}\"\n        return result\n    else:\n        return None\n\n# Example usage\nsentence_1 = \"The weight of the ball is 200 g.\"\nsentence_2 = \"The width is 5mm.\"\n\nprint(extract_measurement(sentence_1))  # Output: 200 gram\nprint(extract_measurement(sentence_2))  # Output: 5 millimeter","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in zip(output, values):\n    print(\"Predicted: \" + extract_measurement(x) + \" ------\" + \"Actual: \" + y)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.877254Z","iopub.status.idle":"2024-09-14T08:39:49.877632Z","shell.execute_reply.started":"2024-09-14T08:39:49.877442Z","shell.execute_reply":"2024-09-14T08:39:49.877470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = forward(ename, img)[0]\nprint(output)\nprint(\"Predicted: \" + extract_measurement(output))\nprint(\"Actual: \" + value)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.878913Z","iopub.status.idle":"2024-09-14T08:39:49.879273Z","shell.execute_reply.started":"2024-09-14T08:39:49.879075Z","shell.execute_reply":"2024-09-14T08:39:49.879091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmp = pd.DataFrame({\"index\": [], \"entity_name\"=[] ,\"prediction\": [], \"actual\": []})","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.880743Z","iopub.status.idle":"2024-09-14T08:39:49.881104Z","shell.execute_reply.started":"2024-09-14T08:39:49.880928Z","shell.execute_reply":"2024-09-14T08:39:49.880946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, record in tqdm(subset.iterrows(), total=len(subset)):\n    img = url_to_image(record[\"image_link\"])\n    ename = record[\"entity_name\"]\n    value = record[\"entity_value\"]\n    \n    pred = extract_measurement(forward(ename, img)[0])\n    \n    cmp.loc[len(cmp)] = {\"entity_name\": ename, \"prediction\": pred, \"actual\": value}","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.882425Z","iopub.status.idle":"2024-09-14T08:39:49.882759Z","shell.execute_reply.started":"2024-09-14T08:39:49.882587Z","shell.execute_reply":"2024-09-14T08:39:49.882604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmp","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.884016Z","iopub.status.idle":"2024-09-14T08:39:49.884401Z","shell.execute_reply.started":"2024-09-14T08:39:49.884221Z","shell.execute_reply":"2024-09-14T08:39:49.884240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmp.loc[len(cmp)] = {\"prediction\": pred, \"actual\": value}","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.885830Z","iopub.status.idle":"2024-09-14T08:39:49.886211Z","shell.execute_reply.started":"2024-09-14T08:39:49.886008Z","shell.execute_reply":"2024-09-14T08:39:49.886026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmp","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:39:49.887929Z","iopub.status.idle":"2024-09-14T08:39:49.888408Z","shell.execute_reply.started":"2024-09-14T08:39:49.888168Z","shell.execute_reply":"2024-09-14T08:39:49.888192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}